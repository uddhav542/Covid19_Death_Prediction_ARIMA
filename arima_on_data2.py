# -*- coding: utf-8 -*-
"""ARIMA_ON_DATA2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ecjFpyELdU3kVhqOOvU1HllsbO1BpQaL

# ARIMA modelling on Covid 19 Dataset
"""

import numpy as np
import pandas as pd
from pandas import DataFrame
import matplotlib.pyplot as plt
from pandas.plotting import autocorrelation_plot
from matplotlib import pyplot
from statsmodels.tsa.ar_model import AutoReg
from sklearn.metrics import mean_squared_error
from math import sqrt

"""### Read Data"""

dataset = pd.read_csv(r'Data2.csv')

dataset.head(5)

"""# Data Preprocessing"""

dataset.drop('End Week',axis=1,inplace=True)

# Filter
dataset = dataset[(dataset["Sex"] == 'Female') & (dataset["Age Group"]=='45-54 Years')]

dataset.drop('Sex',axis=1,inplace=True)
dataset.drop('State',axis=1,inplace=True)
dataset.drop('Total Deaths',axis=1,inplace=True)
dataset.drop('Age Group',axis=1,inplace=True)
dataset.drop('MMWR Week',axis=1,inplace=True)
dataset.drop('Data as of',axis=1,inplace=True)
dataset_copy = dataset.copy()
timeseries = dataset.copy()

dataset.head(5)

plt.plot(dataset)
plt.show()

"""## Auto Correlation ------------->

### The plot includes solid and dashed lines that indicate the 95% and 99% confidence interval for the correlation values. 
### Correlation values above these lines are more significant than those below the line, 
### providing a threshold or cutoff for selecting more relevant lag values.
"""

autocorrelation_plot(timeseries)
plt.show()
# This shows that a value around 31-40 is a good choice for lag value

"""## Moving Average Technique ----------->"""

ts_log = np.log(timeseries)

moving_avg = ts_log.rolling(6).mean()
plt.plot(ts_log)
plt.plot(moving_avg, color='red')

ts_log_moving_avg_diff = ts_log - moving_avg
ts_log_moving_avg_diff.head(6)

ts_log_moving_avg_diff.dropna(inplace=True)

from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):
    ts_log = np.log(timeseries)

    rolmean = ts_log.rolling(5).mean()
    rolstd = ts_log.rolling(5).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries["COVID-19 Deaths"], color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)

    #Perform Dickey-Fuller test:
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)

"""## Moving Average and Removing Stationarity
### Here we have just demonstrated the moving average method tracing the prediction
### The Stationarity can be removed by the Rolling mean method
"""

ts_log = np.log(timeseries)
moving_avg = ts_log.rolling(31).mean()
plt.plot(ts_log)
plt.plot(moving_avg, color='red')

ts_log_moving_avg_diff = ts_log - moving_avg
ts_log_moving_avg_diff.head(5)
ts_log_moving_avg_diff.dropna(inplace=True)
test_stationarity(ts_log_moving_avg_diff)

"""# ARIMA -----------> 
### Train / Validation set
"""

train = dataset[:int(0.7*(len(dataset)))]
valid = dataset[int(0.7*(len(dataset))):]

# pip install pmdarima

from pmdarima import auto_arima
model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)
model_fit = model.fit(train)

forecast = model.predict(n_periods=len(valid))
forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])

#plot the predictions for validation set


plt.plot(train, label='Train')
plt.plot(valid,'o', label='Valid')
plt.plot(forecast,'o', label='Prediction')
plt.xlabel("No of Weeks")
plt.ylabel("No of Deaths")
plt.legend(["Trained Data","Predicted ","Forecasted"], loc ="upper left")
plt.show()
print(model.fit(train).summary())

"""### Error calculation"""

#calculate rmse
from math import sqrt
from sklearn.metrics import mean_squared_error

rms = sqrt(mean_squared_error(valid,forecast))

print('Test RMSE: %.4f' % rms)

"""## ACF and PACF function Plots ------->"""

import numpy as np, pandas as pd
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt
plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})

# Import data
df = pd.read_csv(r'Data2.csv')

# Plotting Functions ------> 
fig, axes = plt.subplots(3, 3, sharex=True)

# Original Series
axes[0, 0].plot(df['COVID-19 Deaths']); axes[0, 0].set_title('Original Series')
plot_acf(df['COVID-19 Deaths'], ax=axes[0, 1])
plot_pacf(df['COVID-19 Deaths'], ax=axes[0, 2])

# 1st Differencing
axes[1, 0].plot(df['COVID-19 Deaths'].diff()); axes[1, 0].set_title('1st Order Differencing')
plot_acf(df['COVID-19 Deaths'].diff().dropna(), ax=axes[1, 1])
plot_pacf(df['COVID-19 Deaths'].diff().dropna(), ax=axes[1, 2])

# 2nd Differencing
axes[2, 0].plot(df['COVID-19 Deaths'].diff().diff()); axes[2, 0].set_title('2nd Order Differencing')
plot_acf(df['COVID-19 Deaths'].diff().diff().dropna(), ax=axes[2, 1])
plot_pacf(df['COVID-19 Deaths'].diff().diff().dropna(), ax=axes[2, 2])



plt.show()

plot_acf(timeseries.diff().diff().dropna(), lags=25)
plt.show()

plot_pacf(timeseries.diff().diff().dropna(), lags=31)
plt.show()

"""### Count of values above the threshold indicates the value of q in ACF and p in PACF

#
"""

#residuals = pd.Dataframe(model_fit.resid)
#residuals.plot()
#plt.show()
# # density plot of residuals
#residuals.plot(kind='kde')
#plt.show()
# # summary stats of residuals
#print(residuals.describe())

# split dataset
X = timeseries.values
print(len(X))
train, test = X[1:len(X)-7], X[len(X)-7:]
# train autoregression
window = 29
model = AutoReg(train, lags=29)
model_fit = model.fit()
coef = model_fit.params
# walk forward over time steps in test
history = train[len(train)-window:]
history = [history[i] for i in range(len(history))]
predictions = list()
for t in range(len(test)):
	length = len(history)
	lag = [history[i] for i in range(length-window,length)]
	yhat = coef[0]
	for d in range(window):
		yhat += coef[d+1] * lag[window-d-1]
	obs = test[t]
	predictions.append(yhat)
	history.append(obs)
	print('predicted=%f, expected=%f' % (yhat, obs))
rmse = sqrt(mean_squared_error(test, predictions))
print('Test RMSE: %.3f' % rmse)
# plot
pyplot.plot(test)
pyplot.plot(predictions, color='red')
pyplot.show()



without